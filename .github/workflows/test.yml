name: Xbox 360 Emulation CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, '3.10', '3.11']
        
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements-test.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libusb-1.0-0-dev libudev-dev
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        pip install -r requirements.txt || echo "No requirements.txt found"
    
    - name: Run unit tests
      run: |
        pytest tests/ -m "unit or not integration" \
          --cov=src \
          --cov-report=xml \
          --cov-report=term-missing \
          --junit-xml=test-results/unit-results.xml \
          -v
    
    - name: Run integration tests
      run: |
        pytest tests/ -m "integration" \
          --junit-xml=test-results/integration-results.xml \
          -v
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: true
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: test-results/

  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
    
    - name: Format checking with black
      run: black --check src/ tests/
    
    - name: Import sorting with isort
      run: isort --check-only src/ tests/
    
    - name: Linting with flake8
      run: flake8 src/ tests/
    
    - name: Type checking with mypy
      run: mypy src/ --ignore-missing-imports

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety
    
    - name: Run bandit security scan
      run: bandit -r src/ -f json -o security-report.json || true
    
    - name: Check for known security vulnerabilities
      run: safety check --json --output security-vulnerabilities.json || true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          security-report.json
          security-vulnerabilities.json

  hardware-simulation:
    name: Hardware Simulation Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        sudo apt-get update
        sudo apt-get install -y qemu-user-static
    
    - name: Run hardware simulation tests
      run: |
        # Mock ARM environment for Pi simulation
        export MOCK_RASPBERRY_PI=1
        pytest tests/ -m "hardware" \
          --junit-xml=test-results/hardware-simulation-results.xml \
          -v || echo "Hardware simulation tests completed with warnings"
    
    - name: Upload hardware test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: hardware-simulation-results
        path: test-results/

  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
    
    - name: Run performance benchmarks
      run: |
        pytest tests/ -m "slow" \
          --benchmark-only \
          --benchmark-json=benchmark-results.json \
          -v
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark-results.json

  build-status:
    name: Build Status
    runs-on: ubuntu-latest
    needs: [test, code-quality, security, hardware-simulation, performance]
    if: always()
    
    steps:
    - name: Check overall status
      run: |
        if [[ "${{ needs.test.result }}" == "success" && 
              "${{ needs.code-quality.result }}" == "success" && 
              "${{ needs.security.result }}" == "success" ]]; then
          echo "✅ All critical checks passed"
          exit 0
        else
          echo "❌ Some critical checks failed"
          echo "Test: ${{ needs.test.result }}"
          echo "Code Quality: ${{ needs.code-quality.result }}"
          echo "Security: ${{ needs.security.result }}"
          echo "Hardware Simulation: ${{ needs.hardware-simulation.result }}"
          echo "Performance: ${{ needs.performance.result }}"
          exit 1
        fi